## What are the given files

* feedback-scraper.py
  * collects the reviews data from google play store for bestsecret application

* data-preprocess.py
  * refines the data and leaves only positive and negative reviews

* data-rebalancing.py
  * collects the negative and positive reviews in similar proportions - resolves the original issue when we have positive and negative reviews in propotions 9 to 1.

* model-tuning.py 
  * tunes the model based on the preprocessed/balanced data - put your data file name inside to differentiate between input data 

* check-model.py 
  * checks the model for a single sentence

* compare models
  * allows to compare base and tuned models for the identical set of reviews

## Резюме Практического Опыта с Трансформерами

---

### 1. Подготовка и Зависимости

1.  **Управление зависимостями:** Вы научились использовать `pip freeze > requirements.txt` для сохранения всех зависимостей проекта и их версий, обеспечивая воспроизводимость кода.
2.  **Критические зависимости:** Вы подтвердили, что для fine-tuning трансформеров необходимы библиотеки **`transformers`**, **`datasets`** и, что критично, **`torch` (PyTorch)** как основной фреймворк для обучения моделей.
3.  **Препроцессинг:** Вы выполнили базовую очистку данных (удаление 3-звездочных отзывов) для преобразования задачи из многоклассовой в более управляемую **бинарную классификацию (Positive/Negative)**.

---

### 2. Выбор Модели и Transfer Learning

1.  **Transfer Learning:** Вы использовали подход **Transfer Learning**, взяв предобученную модель (**RoBERTa-Large**), уже настроенную на общую задачу сентимента (`siebert/sentiment-roberta-large-english`), для адаптации к вашей специфической доменной задаче (отзывам о покупках).
2.  **Проверка базовой модели:** Вы провели важнейший "sanity check" (проверку вменяемости), убедившись, что **базовая модель работает корректно** на тестовых примерах, что позволило точно локализовать проблему в вашем процессе дообучения.
3.  **Сила архитектуры:** Вы работали с архитектурой **RoBERTa**, которая является современным стандартом и улучшением по сравнению с оригинальным BERT.

---

### 3. Fine-Tuning и Диагностика Ошибок

1.  **Роль `Trainer`:** Вы освоили использование высокоуровневого API **`Hugging Face Trainer`** для упрощения процесса обучения, управления чекпоинтами и автоматического запуска оценки.
2.  **Checkpoints:** Вы поняли, что папки вроде `checkpoint-X` — это **контрольные точки**, сохраняемые после определенного количества шагов, а корневая папка должна содержать лучшую финальную модель.
3.  **Проблема Overfitting и Underfitting:** Вы на практике увидели главный конфликт: при **малом объеме данных** (**$N \approx 176$**) модель не может обобщать, а **переобучается** (запоминает) доминирующий класс или случайные паттерны.
4.  **Сбалансированность данных:** Вы осознали, что **сбалансированность (88/88)** критична, но она **не заменяет достаточный объем данных**. На маленьком сбалансированном наборе модель может переобучиться на мелкие, случайные особенности.
5.  **Влияние EPOCHS:** Вы увидели, что для **малого набора данных** даже 3 эпохи слишком много, что приводит к переобучению и нелогичным результатам (например, "absolutely bad experience" → POSITIVE).

---

### 4. Оценка и Метрики

1.  **Метрики для классификации:** Вы научились работать с метрикой **F1-score** и ключевыми параметрами усреднения: **`'weighted'`** (рекомендуется для несбалансированного набора) и **`'macro'`** (хорошо для оценки производительности на классе меньшинства).

Ваш главный вывод: **Качество Fine-Tuning напрямую зависит от достаточного количества релевантных и сбалансированных данных.** Если данных мало, лучше использовать хорошо работающую **базовую модель**, чем сильно "портить" ее на крошечном наборе.